""" Copyright (c) 2020, Daniela Szwarcman and IBM Research
    * Licensed under The MIT License [see LICENSE for details]

    - Retrain CNN model generated by Q-NAS.
"""

import argparse
import os

import numpy as np
import tensorflow as tf

physical_devices = tf.config.list_physical_devices('GPU')
for gpu_instance in physical_devices:
    tf.config.experimental.set_memory_growth(gpu_instance, True)

import qnas_config as cfg
from cnn.input import (Dataloader, Dataset, get_split_deterministic,
                       get_validation_augmentation)
from cnn.metric import gen_dice_coef_threshold
from cnn.model import build_net
from util import init_log


def main(**args):
    logger = init_log(args["log_level"], name=__name__)

    # Get all parameters
    logger.info(f"Getting parameters from evolution ...")
    config = cfg.ConfigParameters(args, phase="analyze")
    config.get_parameters()
    
    gen, ind = args["id_num"].split("_")
    gen = int(gen)
    ind = int(ind)

    config.load_evolved_data(gen, ind)


    num_classes = config.train_spec["num_classes"]
    num_channels = config.train_spec["num_channels"]
    image_size = config.train_spec["image_size"]
    stem_filters = config.train_spec["stem_filters"]
    max_depth = config.train_spec["max_depth"]
    data_path = config.train_spec["data_path"]
    batch_size = config.train_spec["batch_size"]

    patch_size = (image_size, image_size, num_channels)
    
    layer_dict = config.layer_dict
    net_list = config.evolved_params['net']
    if config.cell_list == 'None':
        config.cell_list = None
    cell_list = config.cell_list

    net = build_net(
        input_shape=patch_size,
        num_classes=num_classes,
        stem_filters=stem_filters,
        max_depth=max_depth,
        layer_dict=layer_dict,
        net_list=net_list,
        cell_list=cell_list,
    )
    print('Network: ', net_list)

    net.load_weights(os.path.join(args['experiment_path'], "retrained", "weights.h5"))
    print('Weights loaded')

    #print(net.summary())

    val_augmentation = get_validation_augmentation(patch_size)

    _, val_patients = get_split_deterministic(
        os.path.join(data_path, 'train'),
        fold=0,
        num_splits=5,
        random_state=0,
    )

    val_dataset = Dataset(
        data_path=os.path.join(data_path, 'train'),
        selected=val_patients,
        only_non_empty_slices=True,
    )

    val_dataloader = Dataloader(
        dataset=val_dataset,
        batch_size=batch_size,
        skip_slices=0,
        augmentation=val_augmentation,
        shuffle=False,
    )

    # predict on test dataset
    test_dataset = Dataset(
        data_path=os.path.join(data_path, 'test'),
        selected=None,
        only_non_empty_slices=True,
    )
    
    test_dataloader = Dataloader(
        dataset=test_dataset,
        augmentation=val_augmentation,
        shuffle=False,
    )

    best_threshold = 0.5
    best_dice = 0

    for t in range(100):
        input_d = None
        label = []
        for t in val_dataloader:
            if input_d is None:
                input_d = t[0]
            else:
                input_d = np.vstack((input_d, t[0]))
            label.append(t[1])
        prediction = net.predict(input_d, verbose=0)

        prediction = np.array(prediction)
        label = np.array(label)
    
        val_dice = gen_dice_coef_threshold(label, prediction, t/100)
        if best_dice < val_dice:
            best_threshold = t/100
            best_dice = val_dice

    input_d = None
    label = []
    for t in test_dataloader:
        if input_d is None:
            input_d = t[0]
        else:
            input_d = np.vstack((input_d, t[0]))
        label.append(t[1])
    prediction = net.predict(input_d, verbose=0)

    prediction = np.array(prediction)
    label = np.array(label)
    
    test_dice = gen_dice_coef_threshold(label, prediction, best_threshold)

    print(f"Best validation dice {best_dice} using threshold {best_threshold} -> test dice with same threshold {test_dice}")




if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--experiment_path", type=str, required=True, help="Path to experiment_path."
    )
    parser.add_argument(
        "--id_num",
        type=str,
        required=True,
        help="id_num of the individual to be retrained.",
    )

    parser.add_argument(
        "--log_level",
        choices=["NONE", "INFO", "DEBUG"],
        default="NONE",
        help="Logging information level.",
    )

    arguments = parser.parse_args()

    main(**vars(arguments))