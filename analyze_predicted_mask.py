""" Copyright (c) 2020, Daniela Szwarcman and IBM Research
    * Licensed under The MIT License [see LICENSE for details]

    - Retrain CNN model generated by Q-NAS.
"""

import argparse
import os
from typing import Any
import numpy as np
import tensorflow as tf
from keras import backend as K

physical_devices = tf.config.list_physical_devices('GPU')
for gpu_instance in physical_devices:
    tf.config.experimental.set_memory_growth(gpu_instance, True)

import matplotlib.pyplot as plt
import qnas_config as cfg
from cnn.input import Dataloader, Dataset, get_validation_augmentation
from cnn.loss import gen_dice_coef_loss, gen_dice_coef_weight_avg_loss
from cnn.metric import gen_dice_coef_avg, gen_dice_coef_weight_avg
from util import init_log
import time
import random

def plot_comparison(axs: Any, image_num: int, image: np.ndarray, pred: np.ndarray, label: np.ndarray):
    class_colors = np.linspace(0.0, 1.0, 10) # Colors for each class
    for k, cls in enumerate(np.unique(label)):
        print(cls, class_colors[k])
        if cls == 0:
            continue
        pred_indices = np.nonzero(pred == cls)
        pred[pred_indices] = np.array(class_colors[k])


        label_indices = np.nonzero(label == cls)
        label[label_indices] = np.array(class_colors[k])

    print(np.unique(pred))
    axs[image_num, 0].imshow(image.squeeze(), cmap='gray')
    axs[image_num, 0].imshow(pred.squeeze(), cmap='tab10', alpha=0.5)
    if image_num == 0:
        axs[image_num, 0].set_title('Predicted Label')
    axs[image_num, 0].axis('off')  # Turn off axes for cleaner plot

    axs[image_num, 1].imshow(image.squeeze(), cmap='gray')
    axs[image_num, 1].imshow(label.squeeze(), cmap='tab10', alpha=0.5)
    if image_num == 0:
        axs[image_num, 1].set_title('Real Label')
    axs[image_num, 1].axis('off')  # Turn off axes for cleaner plot

def main(**args):
    logger = init_log(args["log_level"], name=__name__)

    # Get all parameters
    logger.info(f"Getting parameters from evolution ...")
    config = cfg.ConfigParameters(args, phase="analyze")
    config.get_parameters()

    gen, ind = args["id_num"].split("_")
    gen = int(gen)
    ind = int(ind)

    config.load_evolved_data(gen, ind)

    num_channels = config.train_spec["num_channels"]
    image_size = config.train_spec["image_size"]
    data_path = config.train_spec["data_path"]

    patch_size = (image_size, image_size, num_channels)

    net: tf.keras.Model = None

    if config.train_spec["use_loss_class_weights"]:
        def custom_gen_dice_coef_weight_avg_loss(y_true, y_pred):
            return gen_dice_coef_weight_avg_loss(y_true, y_pred, config.train_spec["loss_class_weights"])
        
        def custom_gen_dice_coef_weight_avg(y_true, y_pred):
            return gen_dice_coef_weight_avg(y_true, y_pred, config.train_spec["loss_class_weights"])

        net: tf.keras.Model = tf.keras.models.load_model(os.path.join(args['experiment_path'],  f"retrained" if args['retrained'] else '', "bestmodel"),
                                                        custom_objects={
                                                            'custom_gen_dice_coef_weight_avg': custom_gen_dice_coef_weight_avg,
                                                            'custom_gen_dice_coef_weight_avg_loss': custom_gen_dice_coef_weight_avg_loss,
                                                        })
    else:
       net: tf.keras.Model = tf.keras.models.load_model(os.path.join(args['experiment_path'],  f"retrained" if args['retrained'] else '', "bestmodel"),
                                                        custom_objects={
                                                            'gen_dice_coef_avg': gen_dice_coef_avg,
                                                            'gen_dice_coef_loss': gen_dice_coef_loss,
                                                        })

    val_augmentation = get_validation_augmentation(patch_size)

    # Predict on test dataset
    test_dataset = Dataset(
        data_path=os.path.join(data_path, 'test'),
        selected=None,
        only_non_empty_slices=True,
    )

    test_dataloader = Dataloader(
        dataset=test_dataset,
        augmentation=val_augmentation,  # only resize image
        shuffle=False,
    )

    input_d = None
    label = []
    for t in test_dataloader:
        if input_d is None:
            input_d = t[0]
        else:
            input_d = np.vstack((input_d, t[0]))
        label.append(t[1])
        if len(label) == 50:
            break
    prediction = K.argmax(net.predict(input_d, verbose=0), axis=3)
    label = np.array(label)

    random.seed(int(time.time()))
    random_indices = random.sample(range(len(label)), 3)

    # Plot the comparisons for the 3 random images
    fig, axs = plt.subplots(len(random_indices), 2, figsize=(5, 8))
    for idx, i in enumerate(random_indices):
        plot_comparison(axs, idx, input_d[i][:, :, 0], prediction[i].numpy(), label[i][0, :, :])
    plt.tight_layout()
    plt.savefig(os.path.join(args['experiment_path'], 'predicted_images', f'predicted_image.png'))

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--experiment_path", type=str, required=True, help="Path to experiment_path."
    )
    parser.add_argument(
        "--id_num",
        type=str,
        required=True,
        help="id_num of the individual to be retrained.",
    )

    parser.add_argument(
        "--log_level",
        choices=["NONE", "INFO", "DEBUG"],
        default="NONE",
        help="Logging information level.",
    )

    parser.add_argument(
        "--retrained",
        action='store_true',
        help="If should check the retrained path "
        'Default "True".',
    )

    arguments = parser.parse_args()

    main(**vars(arguments))
